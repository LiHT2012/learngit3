搜索一个好的哈希表会得到 O(1) 复杂度

搜索一个均衡的树会得到 O(log(n)) 复杂度

搜索一个阵列会得到 O(n) 复杂度

最好的排序算法具有 O(n*log(n)) 复杂度

糟糕的排序算法具有 O(n^2) 复杂度


你可以更改算法，以便于节省内存空间，方法是不创建新的序列而是直接修改输入序列。

注：这种算法叫『原地算法』(in-place algorithm)

你可以更改算法，以便于同时使用磁盘空间和少量内存而避免巨量磁盘 I/O。方法是只向内存中加载当前处理的部分。在仅仅100MB的内存缓冲区内排序一个几个GB的表时，这是个很重要的技巧。

注：这种算法叫『外部排序』(external sorting)。

二叉排序树：查询的成本就是树内部的层数。一共有 log(N)层。所以这个查询的成本是 log(N)。

范围查询方法。为了解决这个问题，现代数据库使用了一种修订版的树，叫做B+树。在一个B+树里：
只有最底层的节点（叶子节点）才保存信息（相关表的行位置）
其它节点只是在搜索中用来指引到正确节点的。
在二叉排序树的最底层添加一层

比方说你找到了 M 个后续节点，树总共有 N 个节点。对指定节点的搜索成本是 log(N)，跟上一个树相同。
但是当你找到这个节点，你得通过后续节点的连接得到 M 个后续节点，这需要 M 次运算。那么这次搜索只消耗了 M+log(N) 次运算

在B+树中，插入和删除操作是 O(log(N)) 复杂度。所以有些人听到过使用太多索引不是个好主意这类说法。
没错，你减慢了快速插入/更新/删除表中的一个行的操作，因为数据库需要以代价高昂的每索引 O(log(N)) 运算来更新表的索引。
再者，增加索引意味着给事务管理器带来更多的工作负荷

为了构建一个哈希表，你需要定义：
元素的关键字
    关键字的哈希函数。关键字计算出来的哈希值给出了元素的位置（叫做哈希桶）。
    关键字比较函数。一旦你找到正确的哈希桶，你必须用比较函数在桶内找到你要的元素。

真正的挑战是找到好的哈希函数，让哈希桶里包含非常少的元素。
如果有了好的哈希函数，在哈希表里搜索的时间复杂度是 O(1)。

大多数时候瓶颈在于磁盘 I/O 而不是 CPU 使用。



存取路径
在应用联接运算符（join operators）之前，你首先需要获得数据。以下就是获得数据的方法。
全扫描

如果你读过执行计划，一定看到过『全扫描』（或只是『扫描』）一词。简单的说全扫描就是数据库完整的读一个表或索引。就磁盘 I/O 而言，很明显全表扫描的成本比索引全扫描要高昂。
范围扫描

其他类型的扫描有索引范围扫描，比如当你使用谓词 ” WHERE AGE > 20 AND AGE < 40 ” 的时候它就会发生。

当然，你需要在 AGE 字段上有索引才能用到索引范围扫描。

在第一部分我们已经知道，范围查询的时间成本大约是 log(N)+M，这里 N 是索引的数据量，M 是范围内估测的行数。多亏有了统计我们才能知道 N 和 M 的值（注： M 是谓词 “ AGE > 20 AND AGE < 40 ” 的选择率）。另外范围扫描时，你不需要读取整个索引，因此在磁盘 I/O 方面没有全扫描那么昂贵。
唯一扫描

如果你只需要从索引中取一个值你可以用唯一扫描。
根据 ROW ID 存取

多数情况下，如果数据库使用索引，它就必须查找与索引相关的行，这样就会用到根据 ROW ID 存取的方式。

查询执行器不会直接从文件系统拿数据，而是向缓存管理器要。缓存管理器有一个内存缓存区，叫做缓冲池，从内存读取数据显著地提升数据库性能。


query manager：查询管理器
这部分是数据库的威力所在，在这部分里，一个写得糟糕的查询可以转换成一个快速执行的代码，代码执行的结果被送到客户端管理器。
这个多步骤操作过程如下：

查询首先被解析并判断是否合法
然后被重写，去除了无用的操作并且加入预优化部分
接着被优化以便提升性能，并被转换为可执行代码和数据访问计划。
然后计划被编译
最后，被执行

优化其中的两条规则
视图合并：如果你在查询中使用视图，视图就会转换为它的 SQL 代码。
子查询扁平化：子查询是很难优化的，因此重写器会尝试移除子查询

所有的现代数据库都在用基于成本的优化（即CBO）来优化查询。道理是针对每个运算设置一个成本，通过应用成本最低廉的一系列运算，来找到最佳的降低查询成本的方法。

合并联接是唯一产生排序的联接算法。
注：这个简化的合并联接不区分内表或外表；两个表扮演同样的角色。但是真实的实现方式是不同的，比如当处理重复值时。

合并排序是个很好的算法（但是并非最好的，如果内存足够用的话，还是哈希联接更好

如果两个关系都已经排序，时间复杂度是 O(N+M)
如果两个关系需要排序，时间复杂度是对两个关系排序的成本：O(N*Log(N) + M*Log(M))

多数时候，优化器找到的不是最佳的方案，而是一个『不错』的

最近邻居算法，算法的复杂度是 O(N*log(N)) ，对比一下完全动态规划的 O(3^N)

贪婪算法属于一个叫做启发式算法的大家族，它根据一条规则（或启发），保存上一步找到的方法，『附加』到当前步骤来进一步搜寻解决方法。
有些算法根据特定规则，一步步的应用规则但不总是保留上一步找到的最佳方法。它们统称启发式算法。

基因算法：

    一个方法代表一种可能的完整查询计划
    每一步保留了 P 个方法（即计划），而不是一个。
    0) P 个计划随机创建
    1) 成本最低的计划才会保留
    2) 这些最佳计划混合在一起产生 P 个新的计划
    3) 一些新的计划被随机改写
    4) 1，2，3步重复 T 次
    5) 然后在最后一次循环，从 P 个计划里得到最佳计划。

循环次数越多，计划就越好。

这是魔术？不，这是自然法则：适者生存！

PostgreSQL 实现了基因算法，但我并没有发现它是不是默认使用这种算法的。

DB2 使用贪婪算法和动态规划算法。
DB2 优化器可以让你使用 7 种级别的优化：
对联接使用贪婪算法
    0 – 最小优化，使用索引扫描和嵌套循环联接，避免一些查询重写
        1 – 低级优化
        2 – 完全优化
对联接使用动态规划算法
    3 – 中等优化和粗略的近似法
        5 – 完全优化，使用带有启发式的所有技术
        7 – 完全优化，类似级别5，但不用启发式
        9 – 最大优化，完全不顾开销，考虑所有可能的联接顺序，包括笛卡尔乘积

DB2 的默认级别是 5。
默认的，DB2 对联接排列使用受启发式限制的动态规划算法。


关系型数据库使用事务模型，所以，当其他人在同一时刻使用或修改数据时，你无法得到这部分数据。
数据提取是数据库中速度最慢的操作，所以数据管理器需要足够聪明地获得数据并保存在内存缓冲区内。

为了监控预读的工作状况，现代数据库引入了一个度量叫缓冲/缓存命中率，用来显示请求的数据在缓存中找到而不是从磁盘读取的频率。

注：糟糕的缓存命中率不总是意味着缓存工作状态不佳。

缓冲区保存的是页（最小的数据单位）而不是行（逻辑上/人类习惯的观察数据的方式）。缓冲池内的页如果被修改了但还没有写入磁盘，
就是脏页。有很多算法来决定写入脏页的最佳时机，但这个问题与事务的概念高度关联，

一个ACID事务是一个工作单元，它要保证4个属性：

原子性（Atomicity）: 事务『要么全部完成，要么全部取消』，即使它持续运行10个小时。如果事务崩溃，状态回到事务之前（事务回滚）。
隔离性（Isolation）: 如果2个事务 A 和 B 同时运行，事务 A 和 B 最终的结果是相同的，不管 A 是结束于 B 之前/之后/运行期间。
持久性（Durability）: 一旦事务提交（也就是成功执行）,不管发生什么（崩溃或者出错），数据要保存在数据库中。
一致性（Consistency）: 只有合法的数据（依照关系约束和函数约束）能写入数据库，一致性与原子性和隔离性有关。

悲观锁

原理是：

    如果一个事务需要一条数据
    它就把数据锁住
    如果另一个事务也需要这条数据
    它就必须要等第一个事务释放这条数据
    这个锁叫排他锁。

但是对一个仅仅读取数据的事务使用排他锁非常昂贵，因为这会迫使其它只需要读取相同数据的事务等待。因此就有了另一种锁，共享锁。

共享锁是这样的：

    如果一个事务只需要读取数据A
    它会给数据A加上『共享锁』并读取
    如果第二个事务也需要仅仅读取数据A
    它会给数据A加上『共享锁』并读取
    如果第三个事务需要修改数据A
    它会给数据A加上『排他锁』，但是必须等待另外两个事务释放它们的共享锁。

同样的，如果一块数据被加上排他锁，一个只需要读取该数据的事务必须等待排他锁释放才能给该数据加上共享锁。

由于检查循环是昂贵的（所有锁组成的图表是很庞大的），经常会通过简单的途径解决：使用超时设定。如果一个锁在超时时间内没有加上，
那事务就进入死锁状态。

两段锁协议（Two-Phase Locking Protocol，由 DB2 和 SQL Server使用），在这里，事务分为两个阶段：
成长阶段：事务可以获得锁，但不能释放锁。
收缩阶段：事务可以释放锁（对于已经处理完而且不会再次处理的数据），但不能获得新锁。

所有独占锁必须在事务结束时释放。

事务作出的任何修改必须是或者撤销，或者完成。

http://blog.jobbole.com/100349/
